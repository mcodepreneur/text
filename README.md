How do we use language modeling to get intelligent context informed typo correction? The one on my phone displays the three little suggestions but doesn't correct an error that results in a valid word that is clearly out of context. My proposal is to use recently developed language modeling transformers, not with a giant 70 billion model (I say giant but some of the common ones are up to ~200 billion), but with smaller models that could feasibly give predictions fast enough to correct typing in real time, on a mobile computer like a phone, to identify when the probability of a word (predicting on context with the recently typed word token masked) is very low and there is a very similar word that is very probable. I found success multiplying the token prediction probabilities by their logarithmically mapped similarities, [figure] and defining a threshold of this new combined metric to decide when to correct the target word. Additionally the target word would not be corrected to the top predicted correction, even when it passes the threshold, if the target word itself is in the set of predicted corrections and is above a very small proportion of the top correction (~0.01).
