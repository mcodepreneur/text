{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ef333b-0776-4e7a-9b34-77dc9a9286d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\bills-fish-\n",
      "[nltk_data]     shack\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "from transformers import pipeline, GPT2TokenizerFast, GPT2LMHeadModel, AutoTokenizer, BertForMaskedLM\n",
    "from autocorrect import Speller\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from difflib import SequenceMatcher\n",
    "from string import punctuation\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298822b9-d219-4630-83ce-e1e42d7dac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "topk = 2000  # number of top predicted tokens to retrieve (before excluding non-words) \n",
    "\n",
    "class GPT2:\n",
    "    def __init__(self, model=\"gpt2\"):\n",
    "        self.model     =   GPT2LMHeadModel.from_pretrained(model)\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained(model)\n",
    "        self.model_id  = model\n",
    "    \n",
    "    def get_word_probs(self, sentence, n=topk):  # adapted from raul on stackoverflow\n",
    "        inputs = self.tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(inputs)\n",
    "            predictions = outputs[0]\n",
    "        candidates = predictions[0, -1, :]                          # Get the next token candidates.\n",
    "        topk_i = torch.topk(candidates, n).indices.tolist()         # Get the top k next token candidates.\n",
    "        all_probs = torch.nn.functional.softmax(candidates, dim=-1) # Get the token probabilities for all candidates.\n",
    "        topk_probs = all_probs[topk_i].tolist()                     # Filter the token probabilities for the top k candidates.\n",
    "        topk_tokens = [self.tokenizer.decode([idx]).strip()         # Decode the top k candidates back to words.\n",
    "                       for idx in topk_i]\n",
    "        return list(zip(topk_tokens, topk_probs))\n",
    "\n",
    "class BERT:\n",
    "    def __init__(self, model=\"google-bert/bert-base-uncased\"):\n",
    "        self.model     = BertForMaskedLM.from_pretrained(model)\n",
    "        self.tokenizer =   AutoTokenizer.from_pretrained(model)\n",
    "        self.model_id  = model\n",
    "        \n",
    "    def get_word_probs(self, prompt, topk=topk):                  # Get topk masked token candidates\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "        mask_index  = (inputs.input_ids == self.tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "        mask_logits = logits.squeeze()[mask_index].squeeze()\n",
    "        probs = softmax(mask_logits, dim=-1)\n",
    "        topk = 5000\n",
    "        topk_probs, topk_i = torch.topk(probs, topk, dim=-1)\n",
    "        topk_tokens = np.array([self.tokenizer.decode([i]) for i in topk_i])\n",
    "        return np.hstack((topk_tokens.reshape(-1,1), np.array(topk_probs).reshape(-1,1)))\n",
    "\n",
    "M_GPT2 = GPT2(\"gpt2\")\n",
    "M_BERT = BERT(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28778b24-f3cf-4081-ae8b-234040de1624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    common_len = np.ceil((len(a)+len(b))/2)\n",
    "    adjustment = 0\n",
    "    adjustment_table = {1: 0.5, 2: 0.3, 3: 0.2, 4: 0.1}\n",
    "    if common_len in adjustment_table: adjustment = adjustment_table[common_len]*(np.e**(-k*(np.abs(len(a)-len(b))-ap))-bp)\n",
    "    return SequenceMatcher(None, a, b).ratio() + adjustment\n",
    "def rreplace(string, word, new_word):\n",
    "    start = string.rfind(word)\n",
    "    return string[0:start] + new_word + string[start+len(word):]\n",
    "\n",
    "lemmatizer  = WordNetLemmatizer()\n",
    "lemma       = lambda x: lemmatizer.lemmatize(x)\n",
    "stemmer     = PorterStemmer()\n",
    "stem        = lambda x: stemmer.stem(x)\n",
    "spell       = Speller()\n",
    "wl          = set(nltk.corpus.words.words())\n",
    "log_map     = lambda e: np.vectorize(lambda x: np.power(np.log(x/0.5)/np.log(2), e))  # specify exponent to return vectorized mapping\n",
    "after_slash = lambda x: x[(x.rfind(\"/\")+1 if x.rfind(\"/\") != -1 else 0):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da60ee3e-f0a4-489f-8318-636abf0fd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(string, back_n):\n",
    "    places = reversed(range(1,back_n+1))\n",
    "    if back_n == 0: places = [1, 3, 2]\n",
    "    string = string.strip()\n",
    "    words  = string.split()\n",
    "    last_space = string.rfind(' ')\n",
    "    for n in places:\n",
    "        if n > len(words) or len(words) == 1: break\n",
    "        spelled = False\n",
    "        if n > 1:\n",
    "            model  = M_BERT\n",
    "            masked = \"[MASK]\" + words[-n][-1] if not words[-n][-1].isalpha() else \"[MASK]\"\n",
    "            target = words[-n].strip(punctuation)\n",
    "            prompt = ' '.join(words[:-n] + [masked] + words[len(words)-(n-1):])\n",
    "            target = words[-n].strip(punctuation)\n",
    "            if target != spell(target):\n",
    "                spelled = True\n",
    "        else:\n",
    "            model  = M_GPT2\n",
    "            string = string.strip()\n",
    "            last_space = string.rfind(' ')\n",
    "            prompt = string[:last_space]\n",
    "            target = string[last_space+1:].strip(punctuation)\n",
    "            target = words[-n].strip(punctuation)\n",
    "            if target != spell(target):\n",
    "                spelled = True\n",
    "        probs  = model.get_word_probs(prompt)                \n",
    "        probsp = [(str(word), float(prob), float(similar(target.lower(), word.lower()))) for word, prob in probs if word in wl]\n",
    "        close_probs = [prob for prob in probsp if prob[2] > 0.5 and prob[1] >= min(0.001, probsp[consider_top][1])]\n",
    "        props = [(word, (prob**prob_exp)*log_map(log_exp)(sim)) for word, prob, sim in close_probs]\n",
    "        props = sorted(props, reverse=True, key=lambda x: x[1])\n",
    "        props = [prop for prop in props if prop[1] > 0.000001]\n",
    "        probN = threshold(n)\n",
    "        make_correction = False\n",
    "        if len(props) > 0 and props[0][1] > probN:\n",
    "            make_correction = True\n",
    "            irr_t = props[0][1] * relevency_t\n",
    "            for word, score in props: \n",
    "                if score < irr_t: break\n",
    "                elif target.lower() == word.lower() or stem(target.lower())  == word.lower() or lemma(target.lower()) == word.lower():\n",
    "                    make_correction = False\n",
    "        if make_correction: return (n, props[0][0], spelled)\n",
    "        if spelled: return (n, target, spelled)\n",
    "    return False\n",
    "def process_correction(string, back_n):\n",
    "    corrected = string\n",
    "    words     = string.split()\n",
    "    is_correction = correction(string, back_n)\n",
    "    if is_correction:\n",
    "        n, word, _ = is_correction\n",
    "        words[-n] = word if words[-n][-1] not in punctuation else word + words[-n][-1]\n",
    "        corrected = \" \".join(words)\n",
    "        #is_correction = correction(corrected, back_n)\n",
    "    return corrected if corrected != string else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10948a4e-1770-4dfa-b180-f53c3dd7cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('What if we went to the stove?', 'What if we went to the store?')\n",
      "1: ('when you come in can you remember to feel the cat?', 'when you come in can you remember to feed the cat?')\n",
      "2: ('when you come in can you remember to feed the cad?', 'when you come in can you remember to feed the cat?')\n",
      "3: ('I have to right a note', 'I have to write a note')\n",
      "4: (\"This is Eric. He's going to fry to\", \"This is Eric. He's going to try to\")\n",
      "5: ('do you want any walt or pepper', 'do you want any salt or pepper')\n",
      "6: (\"Please don't forget to turn off the store when\", \"Please don't forget to turn off the stove when\")\n",
      "7: ('are you going to wear the yellow hat or the bed one', 'are you going to wear the yellow hat or the red one')\n",
      "8: ('when do you want to get up to see the fun rise?', 'when do you want to get up to see the sun rise?')\n",
      "9: ('can you go and let my', 'can you go and get my')\n",
      "10: ('can you let my', 'can you let my')\n",
      "11: ('you led us on a wild goose case', 'you led us on a wild goose chase')\n",
      "12: ('when you come over can you remember to being', 'when you come over can you remember to bring')\n",
      "13: ('when you come over can you being the soup', 'when you come over can you bring the soup')\n",
      "14: ('when you come over can you, being the', 'when you come over can you, being the')\n",
      "15: ('I went outside and the wind flew my hat', 'I went outside and the wind blew my hat')\n",
      "16: ('After I get out of the shower I usually growl', 'After I get out of the shower I usually growl')\n",
      "17: (\"Don't step on my wet bug\", \"Don't step on my wet rug, I'm cleaning\")\n",
      "18: ('the rally big bar', 'the really big bar')\n",
      "19: ('I think you need to pat more attention', 'I think you need to pay more attention')\n",
      "20: (\"This method isn't really as grate\", \"This method isn't really as great\")\n",
      "21: (\"Don't step on the wet rug, we're gleaning\", \"Don't step on the wet rug, we're cleaning\")\n",
      "22: ('Who dat', 'Who dat')\n",
      "23: ('When you come over, can you bring the flock we talked', 'When you come over, can you bring the flock we talked')\n",
      "24: ('can you remember to feed my cad?', 'can you remember to feed my cat?')\n",
      "25: ('When you come home can', 'When you come home can')\n",
      "26: ('everything that I want to happen. Im', 'everything that I want to happen. Im')\n",
      "27: (\"I'm really not that tipe\", \"I'm really not that tipe\")\n",
      "28: ('Are you hot as well?', 'Are you hot as well?')\n",
      "29: (\"This isn't the final version, but it'll work\", \"This isn't the final version, but it'll work\")\n",
      "30: ('I just wanted', 'I just wanted')\n",
      "31: ('I want to read a good bool', 'I want to read a good book')\n",
      "32: ('The car drove down the rode', 'The car drove down the road')\n",
      "33: ('They went on a walk in the pouring rein', 'They went on a walk in the pouring rain')\n",
      "34: ('The shoe was way too lose', 'The shoe was way too loose')\n",
      "35: ('He bought a gift for his mother', 'He bought a gift for his mother')\n",
      "36: ('The movie was really exiting', 'The movie was really exciting')\n",
      "37: ('Please bring a piece offering', 'Please bring a peace offering')\n",
      "38: (\"I'll meat you at\", \"I'll meet you at\")\n",
      "39: (\"Let's go out to the bark tomorrow\", \"Let's go out to the park tomorrow\")\n",
      "40: ('Can you tell me a good peace of advice', 'Can you tell me a good piece of advice')\n",
      "41: ('I need to go get some more bread at the barkery', 'I need to go get some more bread at the bakery')\n",
      "42: ('She wanted to file a complain', 'She wanted to file a complaint')\n",
      "43: ('She has a really unique styl', 'She has a really unique style')\n",
      "44: ('The fire truck went dawn the road', 'The fire truck went down the road')\n",
      "45: ('I love the new flwer arrangement', 'I love the new flower arrangement')\n",
      "46: ('Please bare with me', 'Please bear with me')\n",
      "47: (\"Please don't make any load noises\", \"Please don't make any loud noises\")\n",
      "48: (\"Please don't make any loud nose\", \"Please don't make any loud noise\")\n",
      "49: ('The sign read: no praking', 'The sign read: no parking')\n",
      "50: ('The cloths were drying', 'The clothes were drying')\n",
      "51: ('He got a big laugh out of that hoke', 'He got a big laugh out of that joke')\n",
      "52: ('He was a brave solder', 'He was a brave soldier')\n"
     ]
    }
   ],
   "source": [
    "strings = [\n",
    "(\"What if we went to the stove?\",                       \"What if we went to the store?\"),\n",
    "(\"when you come in can you remember to feel the cat?\",  \"when you come in can you remember to feed the cat?\"),\n",
    "(\"when you come in can you remember to feed the cad?\",  \"when you come in can you remember to feed the cat?\"),\n",
    "(\"I have to right a note\",                              \"I have to write a note\"),\n",
    "(\"This is Eric. He's going to fry to\",                  \"This is Eric. He's going to try to\"),\n",
    "(\"do you want any walt or pepper\",                      \"do you want any salt or pepper\"),\n",
    "(\"Please don't forget to turn off the store when\",      \"Please don't forget to turn off the stove when\"),\n",
    "(\"are you going to wear the yellow hat or the bed one\", \"are you going to wear the yellow hat or the red one\"),\n",
    "(\"when do you want to get up to see the fun rise?\",     \"when do you want to get up to see the sun rise?\"),\n",
    "(\"can you go and let my\",                               \"can you go and get my\"),\n",
    "(\"can you let my\",                                      \"can you let my\"),\n",
    "(\"you led us on a wild goose case\",                     \"you led us on a wild goose chase\"),\n",
    "(\"when you come over can you remember to being\",        \"when you come over can you remember to bring\"),\n",
    "(\"when you come over can you being the soup\",           \"when you come over can you bring the soup\"),\n",
    "(\"when you come over can you, being the\",               \"when you come over can you, being the\"),\n",
    "(\"I went outside and the wind flew my hat\",             \"I went outside and the wind blew my hat\"),\n",
    "(\"After I get out of the shower I usually growl\",       \"After I get out of the shower I usually growl\"),\n",
    "(\"Don't step on my wet bug\",                            \"Don't step on my wet rug, I'm cleaning\"),\n",
    "(\"the rally big bar\",                                   \"the really big bar\"),\n",
    "(\"I think you need to pat more attention\",              \"I think you need to pay more attention\"),\n",
    "(\"This method isn't really as grate\",                   \"This method isn't really as great\"),\n",
    "(\"Don't step on the wet rug, we're gleaning\",           \"Don't step on the wet rug, we're cleaning\"),\n",
    "(\"Who dat\",                                             \"Who dat\"),\n",
    "(\"When you come over, can you bring the flock we talked\", \"When you come over, can you bring the flock we talked\"),\n",
    "(\"can you remember to feed my cad?\",                    \"can you remember to feed my cat?\"),\n",
    "(\"When you come home can\",                              \"When you come home can\"),\n",
    "(\"everything that I want to happen. Im\",                \"everything that I want to happen. Im\"),\n",
    "(\"I'm really not that tipe\",                            \"I'm really not that tipe\"),           \n",
    "(\"Are you hot as well?\",                                \"Are you hot as well?\"),\n",
    "(\"This isn't the final version, but it'll work\",        \"This isn't the final version, but it'll work\"),\n",
    "(\"I just wanted\",                                       \"I just wanted\"),\n",
    "(\"I want to read a good bool\",                          \"I want to read a good book\"),\n",
    "(\"The car drove down the rode\",                         \"The car drove down the road\"),\n",
    "(\"They went on a walk in the pouring rein\",             \"They went on a walk in the pouring rain\"),\n",
    "(\"The shoe was way too lose\",                           \"The shoe was way too loose\"),\n",
    "(\"He bought a gift for his mother\",                     \"He bought a gift for his mother\"),\n",
    "(\"The movie was really exiting\",                        \"The movie was really exciting\"),\n",
    "(\"Please bring a piece offering\",                       \"Please bring a peace offering\"),\n",
    "(\"I'll meat you at\",                                    \"I'll meet you at\"),\n",
    "(\"Let's go out to the bark tomorrow\",                   \"Let's go out to the park tomorrow\"),\n",
    "(\"Can you tell me a good peace of advice\",              \"Can you tell me a good piece of advice\"),\n",
    "(\"I need to go get some more bread at the barkery\",     \"I need to go get some more bread at the bakery\"),\n",
    "(\"She wanted to file a complain\",                       \"She wanted to file a complaint\"),\n",
    "(\"She has a really unique styl\",                        \"She has a really unique style\"),\n",
    "(\"The fire truck went dawn the road\",                   \"The fire truck went down the road\"),\n",
    "(\"I love the new flwer arrangement\",                    \"I love the new flower arrangement\"),\n",
    "(\"Please bare with me\",                                 \"Please bear with me\"),\n",
    "(\"Please don't make any load noises\",                   \"Please don't make any loud noises\"),\n",
    "(\"Please don't make any loud nose\",                     \"Please don't make any loud noise\"),\n",
    "(\"The sign read: no praking\" ,                          \"The sign read: no parking\"),\n",
    "(\"The cloths were drying\",                              \"The clothes were drying\"),\n",
    "(\"He got a big laugh out of that hoke\",                 \"He got a big laugh out of that joke\"),\n",
    "(\"He was a brave solder\",                               \"He was a brave soldier\"),\n",
    "# add negatives (sentences not changed), maybe 50/50\n",
    "]\n",
    "for i, x in enumerate(strings): print(f'{i}: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3f5aa2-3d7c-42b5-be74-e297bf89b78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total: 53, true: 32, accuracy: 0.6037735849056604'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_n  = 0  # number of words back from end of string, 1 is just last word, 0 is [1, 3, 2]\n",
    "k       = 1.2  # exponent parameter for exponential decay of word length augmedented SequenceMatcher\n",
    "ap      = 0.57  # exponent parameter\n",
    "bp      = 1  # exponent parameter\n",
    "log_exp      = 5  # exponent parameter for logarithmic mapping\n",
    "prob_exp     = 1.5  # raise probability to power in ((prob**power)*log-sim)\n",
    "consider_top = 100  # max top model word predictions considered\n",
    "relevency_t  = 0.05  # threshold defined by portion of top proposition to exclude much smaller scored propositions for correcting\n",
    "base_t       = 0.0001  # decision threshold for last word: base threshold\n",
    "threshold_e  = 1.5  # exponent for exponential thresholds\n",
    "threshold_t  = \"exponential\"  # function defines decision threshold for word n from end\n",
    "threshold    = {\"constant\":    lambda n: base_t,\n",
    "                \"linear\":      lambda n: base_t + (base_t * (n-1)),\n",
    "                \"exponential\": lambda n: base_t * (n**threshold_e),\n",
    "                \"jump-exp\":    lambda n: base_t * (max(n-1,1)**threshold_e),        # jump thresholds start growing after n=2\n",
    "                \"jump-lin\":    lambda n: base_t + (base_t * max(n-2, 0))\n",
    "               }[threshold_t]\n",
    "\n",
    "y_h = []\n",
    "for x, y in strings: y_h.append(process_correction(x, back_n) == y)\n",
    "y_h = np.array(y_h)\n",
    "f'total: {y_h.shape[0]}, true: {np.array(y_h).sum()}, accuracy: {np.array(y_h).sum()/y_h.shape[0]}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
